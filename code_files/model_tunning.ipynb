{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af4465b-1bcd-42b0-b37e-83e9e47eb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: multi_model_tuner.py\n",
    "# Run with: python multi_model_tuner.py --model EfficientNetB0\n",
    "# or: import functions into notebook and call them.\n",
    "\n",
    "import os, sys, math, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Pretrained model helpers\n",
    "from tensorflow.keras.applications import (\n",
    "    MobileNetV2, EfficientNetB0, InceptionV3, ResNet50, VGG16\n",
    ")\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preproc\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preproc\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preproc\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preproc\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033b36a9-b2a9-4578-ab3b-9a5412f70c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28db5ad-9f6e-44fc-bcfa-fb164301a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae003d21-c4a4-47c9-ae9e-d9c15098c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Config ----------\n",
    "DATA_ROOT = \"data\"   # <- update: path in Colab (upload or mount Drive)\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\n",
    "VAL_DIR   = os.path.join(DATA_ROOT, \"val\")\n",
    "TEST_DIR  = os.path.join(DATA_ROOT, \"test\")  # optional but recommended\n",
    "\n",
    "MODELS_DIR = \"/content/models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35364eb2-4467-4dcd-8b5a-bdf2d4291b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuner / training resource control\n",
    "TRIALS = 6           # number of tuner trials per model (increase if you have time)\n",
    "MAX_TUNER_EPOCHS = 6 # epochs during tuner search (keeps tuning cheap)\n",
    "FINAL_EPOCHS = 30    # final training epochs (with early stopping)\n",
    "BATCH_SIZE_DEFAULT = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5caaf0-e29c-4034-b7be-eed7d7ad03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of model names to run (order)\n",
    "MODEL_LIST = [\"CustomCNN\", \"MobileNetV2\", \"EfficientNetB0\", \"InceptionV3\", \"ResNet50\", \"VGG16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ba8e9d-b7bb-49d4-964c-72b199b69b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ 3) Per-model config (input sizes, preprocessors, base model ref, default batch) ------------\n",
    "MODEL_CONFIG = {\n",
    "    \"CustomCNN\":      {\"input_size\": (224,224), \"preproc\": lambda x: x/255.0, \"batch\": 32, \"base\": None},\n",
    "    \"MobileNetV2\":    {\"input_size\": (224,224), \"preproc\": mobilenet_preproc, \"batch\": 32, \"base\": MobileNetV2},\n",
    "    \"EfficientNetB0\": {\"input_size\": (224,224), \"preproc\": eff_preproc, \"batch\": 32, \"base\": EfficientNetB0},\n",
    "    \"InceptionV3\":    {\"input_size\": (299,299), \"preproc\": inception_preproc, \"batch\": 24, \"base\": InceptionV3},\n",
    "    \"ResNet50\":       {\"input_size\": (224,224), \"preproc\": resnet_preproc, \"batch\": 32, \"base\": ResNet50},\n",
    "    \"VGG16\":          {\"input_size\": (224,224), \"preproc\": vgg_preproc, \"batch\": 16, \"base\": VGG16}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f9b579-73a1-407b-9a53-d920cf775151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(model_name):\n",
    "    cfg = MODEL_CONFIG[model_name]\n",
    "    img_size = cfg[\"input_size\"]\n",
    "    batch = cfg[\"batch\"]\n",
    "    preproc = cfg[\"preproc\"]\n",
    "\n",
    "    # Train augmentation\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=preproc,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.12,\n",
    "        height_shift_range=0.12,\n",
    "        zoom_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preproc)\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preproc)\n",
    "\n",
    "    train_gen = train_datagen.flow_from_directory(TRAIN_DIR, target_size=img_size, batch_size=batch, class_mode='categorical', shuffle=True)\n",
    "    val_gen   = val_datagen.flow_from_directory(VAL_DIR,   target_size=img_size, batch_size=batch, class_mode='categorical', shuffle=False)\n",
    "    test_gen  = None\n",
    "    if os.path.exists(TEST_DIR):\n",
    "        test_gen = test_datagen.flow_from_directory(TEST_DIR, target_size=img_size, batch_size=batch, class_mode='categorical', shuffle=False)\n",
    "\n",
    "    return train_gen, val_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60cb2ad9-8af0-4d01-a10d-fe7cbed59d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights_from_gen(gen):\n",
    "    classes = gen.classes\n",
    "    class_ids = np.unique(classes)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=class_ids, y=classes)\n",
    "    return dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11afc023-9407-40d7-83c9-f4738fa49597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h, title=\"history\"):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    if 'accuracy' in h.history:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(h.history['accuracy'], label='train_acc')\n",
    "        plt.plot(h.history.get('val_accuracy', []), label='val_acc')\n",
    "        plt.legend(); plt.title(f\"{title} - Accuracy\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(h.history['loss'], label='train_loss')\n",
    "    plt.plot(h.history.get('val_loss', []), label='val_loss')\n",
    "    plt.legend(); plt.title(f\"{title} - Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6efa9201-5a28-4bf6-bff5-705a46e0f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_cnn(hp, input_shape, n_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    # conv blocks 2-4\n",
    "    for i in range(hp.Int(\"conv_blocks\", 2, 4)):\n",
    "        filters = hp.Choice(f\"filters_{i}\", [32, 48, 64])\n",
    "        x = layers.Conv2D(filters, (3,3), padding='same', activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hp.Int(\"dense_units\", 64, 256, step=64), activation='relu')(x)\n",
    "    x = layers.Dropout(hp.Float(\"dropout\", 0.2, 0.5, step=0.1))(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    lr = hp.Choice(\"lr\", [1e-3, 1e-4, 1e-5])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28d71779-0e61-4c51-9f34-5977a8c75316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Pretrained model builder factory (for tuner) ----------\n",
    "def make_pretrained_builder(model_name):\n",
    "    cfg = MODEL_CONFIG[model_name]\n",
    "    base_fn = cfg[\"base\"]\n",
    "    input_shape = cfg[\"input_size\"] + (3,)\n",
    "    def builder(hp):\n",
    "        base_model = base_fn(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        base_model.trainable = False\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "        x = base_model(inputs, training=False)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(hp.Float(\"top_dropout\", 0.2, 0.5, step=0.1))(x)\n",
    "        x = layers.Dense(hp.Int(\"dense_units\", 64, 256, step=64), activation='relu')(x)\n",
    "        x = layers.Dropout(hp.Float(\"head_dropout\", 0.2, 0.5, step=0.1))(x)\n",
    "        outputs = layers.Dense(2, activation='softmax')(x)  # placeholder, will adapt later\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        lr = hp.Choice(\"lr\", [1e-3, 1e-4, 1e-5])\n",
    "        model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    return builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc1e312d-6a8c-48c7-a0df-958ddbf4b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ 6) Tuner runner per model ------------\n",
    "def run_tuner_and_train(model_name, trials=TRIALS, max_tuner_epochs=MAX_TUNER_EPOCHS, final_epochs=FINAL_EPOCHS):\n",
    "    print(\"\\n\\n=== START:\", model_name, \"===\\n\")\n",
    "    train_gen, val_gen, test_gen = get_generators(model_name)\n",
    "    n_classes = train_gen.num_classes\n",
    "    input_shape = MODEL_CONFIG[model_name][\"input_size\"] + (3,)\n",
    "    class_weights = compute_class_weights_from_gen(train_gen)\n",
    "    print(\"Detected classes:\", list(train_gen.class_indices.keys()))\n",
    "    print(\"Train samples:\", train_gen.samples, \"Val samples:\", val_gen.samples, \"Test samples:\", test_gen.samples if test_gen else \"No test\")\n",
    "\n",
    "    if model_name == \"CustomCNN\":\n",
    "        def build_fn(hp): return build_custom_cnn(hp, input_shape=input_shape, n_classes=n_classes)\n",
    "    else:\n",
    "        base_builder = make_pretrained_builder(model_name)\n",
    "        def build_fn(hp):\n",
    "            m = base_builder(hp)\n",
    "            m = adapt_model_output(m, n_classes)\n",
    "            # recompile with the chosen LR (m.optimizer already set)\n",
    "            m.compile(optimizer=m.optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            return m\n",
    "\n",
    "    tuner = kt.RandomSearch(\n",
    "        build_fn,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=trials,\n",
    "        executions_per_trial=1,\n",
    "        directory=f\"tuner_logs/{model_name}\",\n",
    "        project_name='hp_search',\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    stop_early = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    print(\"Starting tuner.search... (this will run short trainings to explore HP space)\")\n",
    "    tuner.search(train_gen, validation_data=val_gen, epochs=max_tuner_epochs, callbacks=[stop_early], class_weight=class_weights)\n",
    "\n",
    "    # get best hps\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    print(\"Best HP for\", model_name, \":\", best_hp.values)\n",
    "\n",
    "    # Build best model and train to convergence\n",
    "    best_model = tuner.hypermodel.build(best_hp)\n",
    "    best_model = adapt_model_output(best_model, n_classes)\n",
    "    best_model.compile(optimizer=best_model.optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks for final training\n",
    "    ckpt_path = os.path.join(MODELS_DIR, f\"{model_name}_best.h5\")\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(ckpt_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1),\n",
    "        EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(\"Starting final training for\", model_name)\n",
    "    history = best_model.fit(train_gen, validation_data=val_gen, epochs=final_epochs, callbacks=callbacks, class_weight=class_weights)\n",
    "    plot_history(history, title=model_name + \" final\")\n",
    "\n",
    "    # Evaluate on test if exists\n",
    "    if test_gen:\n",
    "        print(\"Evaluating on test set...\")\n",
    "        best_model = tf.keras.models.load_model(ckpt_path)\n",
    "        preds = best_model.predict(test_gen, verbose=1)\n",
    "        y_pred = np.argmax(preds, axis=1)\n",
    "        y_true = test_gen.classes\n",
    "        class_names = list(test_gen.class_indices.keys())\n",
    "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(10,8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(f\"{model_name} - Confusion Matrix (test)\")\n",
    "        plt.show()\n",
    "\n",
    "    # Save best HP to CSV for recording\n",
    "    try:\n",
    "        import json\n",
    "        hp_json = best_hp.values\n",
    "        with open(os.path.join(MODELS_DIR, f\"{model_name}_best_hp.json\"), \"w\") as f:\n",
    "            json.dump(hp_json, f, indent=2)\n",
    "    except Exception as e:\n",
    "        print(\"Could not save HP:\", e)\n",
    "\n",
    "    return ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895b273b-ea29-451d-829e-0aa7c521cff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 35m 10s]\n",
      "val_accuracy: 0.3424908518791199\n",
      "\n",
      "Best val_accuracy So Far: 0.8397436141967773\n",
      "Total elapsed time: 03h 54m 24s\n",
      "Best HP for CustomCNN : {'conv_blocks': 3, 'filters_0': 64, 'filters_1': 48, 'dense_units': 192, 'dropout': 0.2, 'lr': 0.0001, 'filters_2': 32}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'adapt_model_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m MODEL_LIST:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Skip if user doesn't want certain models; else uncomment all\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>>>>> Running model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name)\n\u001b[1;32m----> 6\u001b[0m     model_file \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tuner_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRIALS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     results[model_name] \u001b[38;5;241m=\u001b[39m model_file\n",
      "Cell \u001b[1;32mIn[15], line 42\u001b[0m, in \u001b[0;36mrun_tuner_and_train\u001b[1;34m(model_name, trials, max_tuner_epochs, final_epochs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Build best model and train to convergence\u001b[39;00m\n\u001b[0;32m     41\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mbuild(best_hp)\n\u001b[1;32m---> 42\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43madapt_model_output\u001b[49m(best_model, n_classes)\n\u001b[0;32m     43\u001b[0m best_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mbest_model\u001b[38;5;241m.\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Callbacks for final training\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'adapt_model_output' is not defined"
     ]
    }
   ],
   "source": [
    "# ------------ 7) Run all models sequentially (CAUTION: time & GPU) ------------\n",
    "results = {}  # store paths & later test accuracies\n",
    "for model_name in MODEL_LIST:\n",
    "    # Skip if user doesn't want certain models; else uncomment all\n",
    "    print(\"\\n>>>>> Running model:\", model_name)\n",
    "    model_file = run_tuner_and_train(model_name, trials=TRIALS)\n",
    "    results[model_name] = model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3b0bdf-645a-4c67-961a-03abce2fd8a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42992\\4153382101.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_generators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test_accuracy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_file\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdf_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n=== Final model comparison ===\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_summary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mchampion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\LabMentix\\fish_classifier_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7192\u001b[0m             )\n\u001b[0;32m   7193\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7194\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7196\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7198\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7199\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\LabMentix\\fish_classifier_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'test_accuracy'"
     ]
    }
   ],
   "source": [
    "# ------------ 8) Final summary: load models and compute test accuracy (if test_dir present) ------------\n",
    "summary = []\n",
    "if os.path.exists(TEST_DIR):\n",
    "    # reuse generators to ensure same target ordering\n",
    "    for model_name, model_file in results.items():\n",
    "        print(\"\\nLoading and evaluating:\", model_name)\n",
    "        _, _, test_gen = get_generators(model_name)\n",
    "        model = tf.keras.models.load_model(model_file)\n",
    "        loss, acc = model.evaluate(test_gen, verbose=0)\n",
    "        summary.append({\"model\": model_name, \"test_accuracy\": acc, \"model_file\": model_file})\n",
    "    df_summary = pd.DataFrame(summary).sort_values(\"test_accuracy\", ascending=False).reset_index(drop=True)\n",
    "    print(\"\\n=== Final model comparison ===\")\n",
    "    display(df_summary)\n",
    "    champion = df_summary.iloc[0]\n",
    "    print(\"Champion model:\", champion['model'], \"file:\", champion['model_file'], \"test_acc:\", champion['test_accuracy'])\n",
    "else:\n",
    "    print(\"No TEST_DIR provided — provide test directory to compute final comparison.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c5fdd-a6ee-4b57-8144-cbd91fec67f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36b5b3-424f-4735-8594-beedba166f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4cf22-a874-4b7e-a477-a6a1dd509685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8850c-3b29-4f32-98c9-319e6b791fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8d3d9-423c-4dc5-b290-08ea9d78a589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9bbfee-c84c-4221-9633-e4654f9cdfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d615e-c2d0-4058-a604-c01c3e0f40f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb296ef-fd06-4f4f-ae9a-5cb1dd165bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c090655d-6fa4-4137-aa6a-17a77306b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4984 images belonging to 11 classes.\n",
      "Found 215 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"data\"\n",
    "IMG_SIZE = (224, 224)  # can be changed per model\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    \"data/train\", target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', subset='training'\n",
    ")\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    \"data/val\", target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', subset='validation'\n",
    ")\n",
    "class_names = list(train_gen.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fbc76c-7954-45fa-a6fc-6998bd5de184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='train_acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "    plt.title(f'{title} Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title(f'{title} Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b7ec6c-ab10-4bf7-8a61-9b41c3dad498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, generator, title):\n",
    "    y_true = generator.classes\n",
    "    y_pred = np.argmax(model.predict(generator), axis=1)\n",
    "    print(f\"Classification Report for {title}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm, annot=False, cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix — {title}')\n",
    "    plt.show()\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return {\n",
    "        \"model\": title,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"precision\": np.mean([report[label][\"precision\"] for label in class_names]),\n",
    "        \"recall\": np.mean([report[label][\"recall\"] for label in class_names]),\n",
    "        \"f1\": np.mean([report[label][\"f1-score\"] for label in class_names])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe1e6ac-d02c-47f7-a508-e8fbbb4ef4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_cnn(hp):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('filters_1', 32, 128, step=32),\n",
    "        kernel_size=(3, 3), activation='relu',\n",
    "        input_shape=IMG_SIZE + (3,)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('filters_2', 64, 256, step=64),\n",
    "        kernel_size=(3, 3), activation='relu'\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('dense_units', 64, 256, step=64),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(layers.Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1)))\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice('lr', [1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec43d5f-03ab-457a-b58a-e94c810539f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff7db8-0439-4a27-9da0-2a60ab8cf7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 09m 20s]\n",
      "val_accuracy: 0.7441860437393188\n",
      "\n",
      "Best val_accuracy So Far: 0.7767441868782043\n",
      "Total elapsed time: 00h 58m 17s\n",
      "\n",
      "Search: Running Trial #5\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "96                |96                |filters_1\n",
      "192               |128               |filters_2\n",
      "192               |128               |dense_units\n",
      "0.3               |0.4               |dropout\n",
      "0.01              |0.001             |lr\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m  1/156\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09:54\u001b[0m 27s/step - accuracy: 0.1250 - loss: 2.3761"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_custom_cnn,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=5,\n",
    "    factor=3,\n",
    "    directory='tuner_logs',\n",
    "    project_name='custom_cnn_fish'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=2,         # stop after 2 epochs without improvement\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(train_gen, validation_data=val_gen, epochs=5, callbacks=[early_stop])\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "model = build_custom_cnn(best_hp)\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=8)\n",
    "plot_history(history, \"Custom CNN\")\n",
    "\n",
    "metrics = evaluate_model(model, val_gen, \"Custom CNN\")\n",
    "pd.DataFrame([metrics])\n",
    "model.save(\"custom_cnn_best.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f57054-0d34-417a-bd2f-797417410123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fish_classifier_env",
   "language": "python",
   "name": "fish_classifier_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
